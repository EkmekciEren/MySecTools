import os
import logging
from typing import Dict, Any, List
import json
import time
import random
from utils.cache_manager import CacheManager
from utils.rate_limit_manager import OpenAIRateLimitManager
from utils.data_chunker import DataChunker
from utils.enhanced_rule_analyzer import EnhancedRuleBasedAnalyzer

logger = logging.getLogger(__name__)

class AIAnalyzer:
    """AI-powered security analysis using OpenAI GPT-4o"""
    
    def __init__(self, api_key=None):
        """
        Initialize AI Analyzer
        
        Args:
            api_key: Custom OpenAI API key to use instead of environment variable
        """
        self.api_key = api_key or os.getenv('OPENAI_API_KEY')
        self.model = os.getenv('AI_MODEL', 'gpt-4o')
        self.max_tokens = int(os.getenv('AI_MAX_TOKENS', '2000'))
        self.temperature = float(os.getenv('AI_TEMPERATURE', '0.3'))
        
        # Rate limiting configuration
        self.max_retries = int(os.getenv('AI_MAX_RETRIES', '3'))
        self.base_delay = float(os.getenv('AI_BASE_DELAY', '1.0'))
        self.max_delay = float(os.getenv('AI_MAX_DELAY', '30.0'))
        self.request_timeout = float(os.getenv('AI_REQUEST_TIMEOUT', '30.0'))
        
        # Cache configuration
        cache_ttl = int(os.getenv('AI_CACHE_TTL', '3600'))  # 1 hour default
        self.cache_manager = CacheManager(ttl_seconds=cache_ttl)
        
        # Rate limit manager
        self.rate_limit_manager = OpenAIRateLimitManager(self.api_key)
        
        # Data chunker for large requests
        self.data_chunker = DataChunker()
        
        # Enhanced rule-based analyzer for fallback
        self.enhanced_rule_analyzer = EnhancedRuleBasedAnalyzer()
        
        # Initialize OpenAI client if available
        self.client = None
        if self.api_key and self.api_key != 'your_openai_api_key_here':
            try:
                from openai import OpenAI
                self.client = OpenAI(
                    api_key=self.api_key,
                    timeout=self.request_timeout
                )
                # Test quota on initialization (async, don't block startup)
                self._test_quota_async()
            except ImportError:
                logger.error("OpenAI library not installed")
    
    def _test_quota_async(self):
        """Test quota asynchronously without blocking initialization"""
        try:
            # Try a minimal request to check quota
            test_response = self.client.chat.completions.create(
                model=self.model,
                messages=[{"role": "user", "content": "Hi"}],
                max_tokens=1,
                temperature=0
            )
            logger.debug("âœ… OpenAI quota test passed")
        except Exception as e:
            error_str = str(e).lower()
            if 'quota' in error_str or 'insufficient_quota' in error_str:
                self.rate_limit_manager.rate_limit.quota_exceeded = True
                logger.warning("ğŸš¨ OpenAI quota exceeded detected on startup - rule-based analysis will be used")
            else:
                logger.debug(f"Quota test failed with: {str(e)}")
    
    def _make_openai_request(self, messages, max_tokens=None, temperature=None):
        """
        Make OpenAI API request with comprehensive rate limiting
        
        Args:
            messages: List of messages for the chat completion
            max_tokens: Maximum tokens for response
            temperature: Temperature for response generation
            
        Returns:
            OpenAI response object
            
        Raises:
            Exception: If all retries fail
        """
        # Early exit if quota exceeded
        if self.rate_limit_manager.rate_limit.quota_exceeded:
            raise Exception("insufficient_quota: Quota exceeded, using rule-based analysis")
        
        if not self.client:
            raise Exception("OpenAI client not initialized")
        
        max_tokens = max_tokens or self.max_tokens
        temperature = temperature or self.temperature
        
        # Estimate total tokens for request
        request_text = json.dumps(messages, ensure_ascii=False)
        estimated_request_tokens = self.data_chunker.estimate_tokens(request_text)
        estimated_total_tokens = estimated_request_tokens + max_tokens
        
        # Check rate limits before making request
        if not self.rate_limit_manager.wait_if_needed(estimated_total_tokens):
            raise Exception("Rate limit exceeded and cannot proceed")
        
        for attempt in range(self.max_retries + 1):  # +1 for initial attempt
            try:
                # Double-check rate limits just before request
                can_proceed, reason, wait_seconds = self.rate_limit_manager.can_make_request(estimated_total_tokens)
                if not can_proceed:
                    if wait_seconds > 0:
                        logger.warning(f"Last-minute rate limit hit: {reason}, waiting {wait_seconds}s")
                        time.sleep(wait_seconds + 1)
                    else:
                        raise Exception(f"Rate limit exceeded: {reason}")
                
                logger.debug(f"OpenAI API request attempt {attempt + 1}/{self.max_retries + 1}")
                logger.debug(f"Estimated tokens: {estimated_total_tokens}")
                
                # Make the actual request
                response = self.client.chat.completions.create(
                    model=self.model,
                    messages=messages,
                    max_tokens=max_tokens,
                    temperature=temperature
                )
                
                # Update rate limits from response headers if available
                if hasattr(response, '_response') and hasattr(response._response, 'headers'):
                    self.rate_limit_manager.update_from_headers(dict(response._response.headers))
                
                # Record successful request
                actual_tokens = getattr(response.usage, 'total_tokens', estimated_total_tokens) if hasattr(response, 'usage') else estimated_total_tokens
                self.rate_limit_manager.record_request(actual_tokens)
                
                logger.debug(f"OpenAI API request successful, tokens used: {actual_tokens}")
                return response
                
            except Exception as e:
                error_str = str(e).lower()
                
                # Check if it's a rate limit error
                if '429' in error_str or 'quota' in error_str or 'rate limit' in error_str:
                    # Check for quota exhaustion (permanent failure)
                    if 'insufficient_quota' in error_str or 'exceeded your current quota' in error_str:
                        self.rate_limit_manager.rate_limit.quota_exceeded = True
                        logger.error("ğŸš¨ OpenAI quota exceeded - switching to rule-based analysis permanently")
                        raise e  # Re-raise to trigger fallback
                    
                    # Regular rate limiting - retry with backoff
                    if attempt < self.max_retries:
                        # Progressive backoff with rate limit awareness
                        base_delay = self.base_delay * (2 ** attempt)
                        jitter = random.uniform(0, 1)
                        
                        # If we know we're hitting rate limits, wait longer
                        if 'quota' in error_str:
                            # Quota exhausted - wait longer
                            delay = min(base_delay * 3 + jitter, self.max_delay)
                        else:
                            # Regular rate limit - shorter wait
                            delay = min(base_delay + jitter, self.max_delay)
                        
                        logger.warning(f"Rate limit hit, retrying in {delay:.2f} seconds (attempt {attempt + 1})")
                        time.sleep(delay)
                        continue
                    else:
                        logger.error("All retry attempts exhausted for rate limit error")
                        raise e
                
                # For non-rate-limit errors, don't retry
                logger.error(f"OpenAI API error: {str(e)}")
                raise e
        
        raise Exception("Maximum retry attempts reached")

    def _assess_threat_level(self, analysis_data: Dict[str, Any]) -> str:
        """
        Assess overall threat level from analysis data
        
        Returns:
            'HIGH', 'MEDIUM', or 'LOW'
        """
        threat_score = 0
        
        # URLScan threats
        urlscan = analysis_data.get('urlscan_data', {})
        if urlscan and 'error' not in urlscan:
            malicious = urlscan.get('malicious_domains', 0)
            suspicious = urlscan.get('suspicious_domains', 0)
            threat_score += malicious * 3 + suspicious * 1
        
        # VirusTotal threats
        vt = analysis_data.get('virustotal_data', {})
        if vt and 'error' not in vt:
            malicious = vt.get('malicious_count', 0)
            suspicious = vt.get('suspicious_count', 0)
            threat_score += malicious * 2 + suspicious * 1
        
        # AbuseIPDB threats
        abuse = analysis_data.get('abuseipdb_data', {})
        if abuse and 'error' not in abuse:
            confidence = abuse.get('abuse_confidence', 0)
            if confidence > 75:
                threat_score += 3
            elif confidence > 50:
                threat_score += 2
            elif confidence > 25:
                threat_score += 1
        
        if threat_score >= 5:
            return 'HIGH'
        elif threat_score >= 2:
            return 'MEDIUM'
        else:
            return 'LOW'
    
    def _source_has_threats(self, source: str, data: dict) -> bool:
        """Check if a data source has any threats worth AI analysis"""
        if source == 'urlscan_data':
            return data.get('malicious_domains', 0) > 0 or data.get('suspicious_domains', 0) > 0
        elif source == 'virustotal_data':
            return data.get('malicious_count', 0) > 0 or data.get('suspicious_count', 0) > 0
        elif source == 'abuseipdb_data':
            return data.get('abuse_confidence', 0) > 25
        return False

    def analyze_step_by_step(self, target: str, analysis_data: Dict[str, Any]) -> Dict[str, Any]:
        """
        Generate step-by-step AI analysis of security data with chunking support
        
        Args:
            target: The analyzed target
            analysis_data: Combined data from all security APIs
            
        Returns:
            Dictionary with individual analyses and final summary
        """
        # Rate limit durumunu kontrol et - Free tier iÃ§in daha agresif threshold
        rate_status = self.rate_limit_manager.get_status()
        
        # Free tier iÃ§in %85 threshold (daha agresif)
        if (rate_status.get('request_usage_percent', 0) > 85 or 
            rate_status.get('token_usage_percent', 0) > 85):
            logger.info(f"High rate limit usage detected (free tier), using chunked analysis for {target}")
            return self.analyze_with_chunking(target, analysis_data)
        
        # Normal step-by-step analiz
        return self._analyze_step_by_step_normal(target, analysis_data)
    
    def _analyze_step_by_step_normal(self, target: str, analysis_data: Dict[str, Any]) -> Dict[str, Any]:
        """Normal step-by-step analiz (eski yÃ¶ntem)"""
        # Check cache first
        cached_result = self.cache_manager.get_cached_analysis(target, analysis_data)
        if cached_result:
            logger.info(f"Returning cached analysis for target: {target}")
            return cached_result
        
        # Check if quota is exceeded (early exit)
        if self.rate_limit_manager.rate_limit.quota_exceeded:
            logger.warning("OpenAI quota exceeded - using rule-based analysis")
            fallback_result = self._generate_comprehensive_fallback_analysis(target, analysis_data)
            fallback_result['ai_error_message'] = "âš ï¸ OpenAI quota aÅŸÄ±ldÄ±. Kural tabanlÄ± analiz kullanÄ±lÄ±yor..."
            self.cache_manager.save_analysis_to_cache(target, analysis_data, fallback_result)
            return fallback_result
        
        if not self.client:
            fallback_result = self._generate_comprehensive_fallback_analysis(target, analysis_data)
            fallback_result['ai_error_message'] = "âš ï¸ AI analiz yapÄ±lamadÄ±: API anahtarÄ± yapÄ±landÄ±rÄ±lmamÄ±ÅŸ. Kural tabanlÄ± analiz uygulanÄ±yor..."
            return fallback_result
        
        # Quick quota test before starting analysis
        try:
            # Make a minimal test request first to check quota
            test_response = self._make_openai_request([
                {"role": "user", "content": "test"}
            ], max_tokens=1, temperature=0)
            logger.debug("Quota test passed, proceeding with analysis")
        except Exception as e:
            error_str = str(e).lower()
            if 'quota' in error_str or 'insufficient_quota' in error_str:
                self.rate_limit_manager.rate_limit.quota_exceeded = True
                logger.error("ğŸš¨ Quota exceeded detected in test request - switching to rule-based analysis")
                fallback_result = self._generate_comprehensive_fallback_analysis(target, analysis_data)
                fallback_result['ai_error_message'] = "âš ï¸ OpenAI quota aÅŸÄ±ldÄ±. Kural tabanlÄ± analiz kullanÄ±lÄ±yor..."
                self.cache_manager.save_analysis_to_cache(target, analysis_data, fallback_result)
                return fallback_result
            # For other errors, continue with normal flow
            logger.warning(f"Quota test failed with non-quota error: {str(e)}")
        
        try:
            # First, check if we need AI analysis or if rule-based is sufficient
            threat_level = self._assess_threat_level(analysis_data)
            
            # For low threat levels, use rule-based analysis to save API quota
            if threat_level == 'LOW' and os.getenv('AI_CONSERVATIVE_MODE', 'true').lower() == 'true':
                logger.info("Using rule-based analysis for low-threat target to conserve API quota")
                fallback_result = self._generate_comprehensive_fallback_analysis(target, analysis_data)
                fallback_result['ai_error_message'] = "â„¹ï¸ API kotasÄ± korunmasÄ± iÃ§in kural tabanlÄ± analiz kullanÄ±ldÄ± (dÃ¼ÅŸÃ¼k risk tespit edildi)"
                
                # Cache the result
                self.cache_manager.save_analysis_to_cache(target, analysis_data, fallback_result)
                return fallback_result
            
            step_analyses = {}
            data_sources = ['urlscan_data', 'virustotal_data', 'abuseipdb_data']
            
            # Step 1: Analyze each data source individually - only if they have threats
            for source in data_sources:
                if source in analysis_data and analysis_data[source] and 'error' not in analysis_data[source]:
                    # Check if this source has any threats worth AI analysis
                    if self._source_has_threats(source, analysis_data[source]):
                        step_analyses[source] = self._analyze_single_source(source, analysis_data[source])
                    else:
                        # Use rule-based for clean sources
                        step_analyses[source] = self._generate_step_fallback_analysis(source, analysis_data[source], "clean_source")
                else:
                    step_analyses[source] = f"{source.replace('_data', '').title()} verisi mevcut deÄŸil veya hatalÄ±."
            
            # Step 2: Generate comprehensive final analysis only if high/medium threat
            try:
                if threat_level in ['HIGH', 'MEDIUM']:
                    final_analysis = self._generate_final_comprehensive_analysis(target, analysis_data, step_analyses)
                    ai_error_message = None  # Success case
                else:
                    # Use rule-based for low threats
                    final_analysis = self._generate_fallback_comprehensive_analysis(analysis_data, "low_threat")
                    ai_error_message = "â„¹ï¸ DÃ¼ÅŸÃ¼k risk seviyesi nedeniyle kural tabanlÄ± analiz kullanÄ±ldÄ±"
            except Exception as final_error:
                logger.warning(f"Final comprehensive analysis failed: {str(final_error)}")
                final_analysis = self._generate_fallback_comprehensive_analysis(analysis_data, str(final_error))
                
                # Hata tÃ¼rÃ¼ne gÃ¶re kullanÄ±cÄ± dostu mesaj belirleme
                error_str = str(final_error).lower()
                if 'quota' in error_str or '429' in error_str:
                    ai_error_message = "âš ï¸ AI analiz yapÄ±lamadÄ±: OpenAI API kotasÄ± aÅŸÄ±ldÄ±. Kural tabanlÄ± analiz uygulanÄ±yor..."
                elif 'timeout' in error_str:
                    ai_error_message = "âš ï¸ AI analiz yapÄ±lamadÄ±: BaÄŸlantÄ± zaman aÅŸÄ±mÄ±. Kural tabanlÄ± analiz uygulanÄ±yor..."
                elif 'authentication' in error_str or 'unauthorized' in error_str:
                    ai_error_message = "âš ï¸ AI analiz yapÄ±lamadÄ±: API anahtarÄ± geÃ§ersiz. Kural tabanlÄ± analiz uygulanÄ±yor..."
                else:
                    ai_error_message = "âš ï¸ AI analiz yapÄ±lamadÄ±: Teknik bir hata oluÅŸtu. Kural tabanlÄ± analiz uygulanÄ±yor..."
            
            result = {
                'step_by_step_analysis': step_analyses,
                'final_comprehensive_analysis': final_analysis,
                'analysis_method': 'ai_powered_step_by_step',
                'ai_error_message': ai_error_message,
                'threat_level': threat_level
            }
            
            # Cache the result
            self.cache_manager.save_analysis_to_cache(target, analysis_data, result)
            
            return result
            
        except Exception as e:
            logger.warning(f"AI step-by-step analysis error: {str(e)}")
            fallback_result = self._generate_comprehensive_fallback_analysis(target, analysis_data)
            
            # Hata tÃ¼rÃ¼ne gÃ¶re kullanÄ±cÄ± dostu mesaj belirleme
            error_str = str(e).lower()
            if 'quota' in error_str or '429' in error_str:
                fallback_result['ai_error_message'] = "âš ï¸ AI analiz yapÄ±lamadÄ±: OpenAI API kotasÄ± aÅŸÄ±ldÄ±. Kural tabanlÄ± analiz uygulanÄ±yor..."
            elif 'timeout' in error_str:
                fallback_result['ai_error_message'] = "âš ï¸ AI analiz yapÄ±lamadÄ±: BaÄŸlantÄ± zaman aÅŸÄ±mÄ±. Kural tabanlÄ± analiz uygulanÄ±yor..."
            elif 'authentication' in error_str or 'unauthorized' in error_str:
                fallback_result['ai_error_message'] = "âš ï¸ AI analiz yapÄ±lamadÄ±: API anahtarÄ± geÃ§ersiz. Kural tabanlÄ± analiz uygulanÄ±yor..."
            else:
                fallback_result['ai_error_message'] = "âš ï¸ AI analiz yapÄ±lamadÄ±: Teknik bir hata oluÅŸtu. Kural tabanlÄ± analiz uygulanÄ±yor..."
            
            # Cache fallback result too
            self.cache_manager.save_analysis_to_cache(target, analysis_data, fallback_result)
            return fallback_result

    def _analyze_single_source(self, source_name: str, data: dict) -> str:
        """Analyze data from a single source"""
        try:
            # Check if we're in demo mode or have API issues
            if os.getenv('DEMO_MODE', 'false').lower() == 'true':
                return self._generate_demo_analysis(source_name, data)
            
            # Create a focused prompt for this specific source
            prompt = f"""
            Siber gÃ¼venlik uzmanÄ± olarak, {source_name} veri kaynaÄŸÄ±ndan gelen aÅŸaÄŸÄ±daki analiz verilerini deÄŸerlendir:
            
            {json.dumps(data, indent=2, ensure_ascii=False)}
            
            Bu veriler hakkÄ±nda:
            1. Tespit edilen risk unsurlarÄ±
            2. GÃ¼venlik deÄŸerlendirmesi
            3. Bu kaynaÄŸa Ã¶zgÃ¼ Ã¶neriler
            
            KÄ±sa ve net bir analiz yap (maksimum 3-4 cÃ¼mle):
            """
            
            response = self._make_openai_request([
                {"role": "system", "content": "Sen bir siber gÃ¼venlik uzmanÄ±sÄ±n. Teknik verileri analiz edip anlaÅŸÄ±lÄ±r deÄŸerlendirmeler yapÄ±yorsun."},
                {"role": "user", "content": prompt}
            ], max_tokens=300, temperature=0.3)
            
            return response.choices[0].message.content.strip()
            
        except Exception as e:
            # If API fails, provide fallback analysis
            return self._generate_step_fallback_analysis(source_name, data, str(e))

    def _generate_final_comprehensive_analysis(self, target: str, analysis_data: Dict[str, Any], step_analyses: Dict[str, str]) -> str:
        """Generate final comprehensive analysis based on all step analyses"""
        try:
            # Combine all individual analyses
            combined_analyses = "\n\n".join([f"### {key.replace('_data', '').title()} Analizi:\n{analysis}" 
                                           for key, analysis in step_analyses.items()])
            
            # Get summary statistics
            summary_stats = self._get_analysis_summary_stats(analysis_data)
            
            prompt = f"""
Hedef: {target}

AÅŸaÄŸÄ±daki bireysel analizleri deÄŸerlendirdim:

{combined_analyses}

## Ã–zet Ä°statistikler:
{json.dumps(summary_stats, indent=2, ensure_ascii=False)}

TÃ¼m bu analizleri birleÅŸtirerek kapsamlÄ± bir gÃ¼venlik deÄŸerlendirmesi yap:

1. **GENEL RÄ°SK SEVÄ°YESÄ°** (Kritik/YÃ¼ksek/Orta/DÃ¼ÅŸÃ¼k/Minimal)

2. **ANA BULGULAR**
   - En Ã¶nemli 3-5 bulguyu listele

3. **TEHDÄ°T ANALÄ°ZÄ°**
   - Tespit edilen potansiyel tehditler
   - Risk faktÃ¶rleri

4. **GÃœVENÄ°LÄ°RLÄ°K DEÄERLENDÄ°RMESÄ°**
   - Veri kaynaklarÄ±nÄ±n tutarlÄ±lÄ±ÄŸÄ±
   - Analiz gÃ¼venilirliÄŸi

5. **Ã–NERÄ°LER**
   - KullanÄ±cÄ±ya Ã¶zel Ã¶neriler
   - AlÄ±nmasÄ± gereken Ã¶nlemler

6. **SONUÃ‡**
   - Net bir sonuÃ§ ve Ã¶nerilen eylem

Profesyonel, detaylÄ± ve anlaÅŸÄ±lÄ±r bir analiz sun. TÃ¼rkÃ§e olarak yaz.
"""
            
            response = self._make_openai_request([
                {
                    "role": "system",
                    "content": "Sen kÄ±demli bir siber gÃ¼venlik uzmanÄ±sÄ±n. Ã‡eÅŸitli kaynaklardan gelen gÃ¼venlik verilerini birleÅŸtirerek kapsamlÄ± risk deÄŸerlendirmeleri yapÄ±yorsun. Analizin profesyonel, objektif ve pratik olmalÄ±."
                },
                {
                    "role": "user",
                    "content": prompt
                }
            ], max_tokens=self.max_tokens, temperature=self.temperature)
            
            return response.choices[0].message.content.strip()
            
        except Exception as e:
            logger.warning(f"Final comprehensive analysis error: {str(e)}")
            
            # Quota hatasÄ± gibi Ã¶nemli hatalar iÃ§in exception'Ä± yeniden at
            error_str = str(e).lower()
            if 'quota' in error_str or '429' in error_str or 'authentication' in error_str or 'unauthorized' in error_str:
                raise e  # Exception'Ä± yukarÄ± at ki hata mesajÄ± ayarlanabilsin
            
            # DiÄŸer hatalar iÃ§in fallback dÃ¶ndÃ¼r
            return self._generate_fallback_comprehensive_analysis(analysis_data, str(e))

    def analyze_with_chunking(self, target: str, analysis_data: Dict[str, Any]) -> Dict[str, Any]:
        """
        Analyze using chunk-based approach for better rate limit management
        
        Args:
            target: The analyzed target
            analysis_data: Combined data from all security APIs
            
        Returns:
            Dictionary with chunked analyses and final summary
        """
        # Check cache first
        cached_result = self.cache_manager.get_cached_analysis(target, analysis_data)
        if cached_result:
            logger.info(f"Returning cached analysis for target: {target}")
            return cached_result
        
        # Check if quota is exceeded (early exit)
        if self.rate_limit_manager.rate_limit.quota_exceeded:
            logger.warning("OpenAI quota exceeded - using rule-based analysis for chunked request")
            fallback_result = self._generate_comprehensive_fallback_analysis(target, analysis_data)
            fallback_result['ai_error_message'] = "âš ï¸ OpenAI quota aÅŸÄ±ldÄ±. Kural tabanlÄ± analiz kullanÄ±lÄ±yor..."
            self.cache_manager.save_analysis_to_cache(target, analysis_data, fallback_result)
            return fallback_result
        
        if not self.client:
            fallback_result = self._generate_comprehensive_fallback_analysis(target, analysis_data)
            fallback_result['ai_error_message'] = "âš ï¸ AI analiz yapÄ±lamadÄ±: API anahtarÄ± yapÄ±landÄ±rÄ±lmamÄ±ÅŸ. Kural tabanlÄ± analiz uygulanÄ±yor..."
            return fallback_result
        
        try:
            # Assess threat level
            threat_level = self._assess_threat_level(analysis_data)
            
            # For low threat levels in conservative mode, use rule-based analysis
            if threat_level == 'LOW' and os.getenv('AI_CONSERVATIVE_MODE', 'true').lower() == 'true':
                logger.info("Using rule-based analysis for low-threat target to conserve API quota")
                fallback_result = self._generate_comprehensive_fallback_analysis(target, analysis_data)
                fallback_result['ai_error_message'] = "â„¹ï¸ API kotasÄ± korunmasÄ± iÃ§in kural tabanlÄ± analiz kullanÄ±ldÄ± (dÃ¼ÅŸÃ¼k risk tespit edildi)"
                self.cache_manager.save_analysis_to_cache(target, analysis_data, fallback_result)
                return fallback_result
            
            # Create chunks from analysis data
            chunks = self.data_chunker.chunk_analysis_data(analysis_data)
            prompts = self.data_chunker.create_analysis_prompts(chunks, target)
            
            # Analyze each chunk
            chunk_results = {}
            successful_chunks = 0
            
            for i, (prompt, estimated_tokens) in enumerate(prompts):
                chunk_source = chunks[i]['source']
                
                try:
                    # Check if we should process this chunk
                    if not self._should_process_chunk(chunks[i], threat_level):
                        chunk_results[chunk_source] = self._generate_step_fallback_analysis(
                            chunk_source, chunks[i]['data'], "low_priority_skipped"
                        )
                        continue
                    
                    # Make chunked AI request
                    response = self._make_openai_request([
                        {"role": "system", "content": "Sen bir siber gÃ¼venlik uzmanÄ±sÄ±n. KÄ±sa ve net analizler yapÄ±yorsun."},
                        {"role": "user", "content": prompt}
                    ], max_tokens=300, temperature=0.3)  # Free tier iÃ§in optimize edilmiÅŸ
                    
                    chunk_results[chunk_source] = response.choices[0].message.content.strip()
                    successful_chunks += 1
                    
                    # Small delay between chunks to be respectful
                    time.sleep(0.5)
                    
                except Exception as chunk_error:
                    logger.warning(f"Chunk analysis failed for {chunk_source}: {str(chunk_error)}")
                    chunk_results[chunk_source] = self._generate_step_fallback_analysis(
                        chunk_source, chunks[i]['data'], str(chunk_error)
                    )
            
            # Generate final synthesis if we have successful chunks
            try:
                if successful_chunks > 0:
                    final_analysis = self._synthesize_chunk_results(target, chunk_results, analysis_data)
                    ai_error_message = None
                else:
                    # All chunks failed, use fallback
                    final_analysis = self._generate_fallback_comprehensive_analysis(analysis_data, "all_chunks_failed")
                    ai_error_message = "âš ï¸ TÃ¼m AI chunk'larÄ± baÅŸarÄ±sÄ±z oldu. Kural tabanlÄ± analiz uygulanÄ±yor..."
                    
            except Exception as synthesis_error:
                logger.warning(f"Final synthesis failed: {str(synthesis_error)}")
                final_analysis = self._generate_fallback_comprehensive_analysis(analysis_data, str(synthesis_error))
                
                error_str = str(synthesis_error).lower()
                if 'quota' in error_str or '429' in error_str:
                    ai_error_message = "âš ï¸ AI sentez aÅŸamasÄ±nda quota aÅŸÄ±ldÄ±. ParÃ§alÄ± analiz sonuÃ§larÄ± kullanÄ±lÄ±yor..."
                else:
                    ai_error_message = "âš ï¸ AI sentez baÅŸarÄ±sÄ±z. ParÃ§alÄ± analiz sonuÃ§larÄ± kullanÄ±lÄ±yor..."
            
            result = {
                'chunk_analyses': chunk_results,
                'final_comprehensive_analysis': final_analysis,
                'analysis_method': 'chunked_ai_analysis',
                'successful_chunks': successful_chunks,
                'total_chunks': len(prompts),
                'threat_level': threat_level,
                'ai_error_message': ai_error_message,
                'rate_limit_status': self.rate_limit_manager.get_status()
            }
            
            # Cache the result
            self.cache_manager.save_analysis_to_cache(target, analysis_data, result)
            return result
            
        except Exception as e:
            logger.warning(f"Chunked AI analysis error: {str(e)}")
            fallback_result = self._generate_comprehensive_fallback_analysis(target, analysis_data)
            
            error_str = str(e).lower()
            if 'quota' in error_str or '429' in error_str:
                fallback_result['ai_error_message'] = "âš ï¸ AI analiz yapÄ±lamadÄ±: OpenAI API kotasÄ± aÅŸÄ±ldÄ±. Kural tabanlÄ± analiz uygulanÄ±yor..."
            else:
                fallback_result['ai_error_message'] = "âš ï¸ AI analiz yapÄ±lamadÄ±: Teknik bir hata oluÅŸtu. Kural tabanlÄ± analiz uygulanÄ±yor..."
                
            self.cache_manager.save_analysis_to_cache(target, analysis_data, fallback_result)
            return fallback_result

    def _should_process_chunk(self, chunk: Dict[str, Any], threat_level: str) -> bool:
        """Chunk'Ä±n iÅŸlenip iÅŸlenmeyeceÄŸini belirle"""
        # YÃ¼ksek risk durumunda tÃ¼m chunk'larÄ± iÅŸle
        if threat_level == 'HIGH':
            return True
        
        # Orta risk durumunda ana chunk'larÄ± iÅŸle
        if threat_level == 'MEDIUM':
            return chunk.get('chunk_type') != 'categories'
        
        # DÃ¼ÅŸÃ¼k risk durumunda sadece temel chunk'larÄ± iÅŸle
        return chunk.get('chunk_type') in ['single_source', 'basic_info']

    def _synthesize_chunk_results(self, target: str, chunk_results: Dict[str, str], analysis_data: Dict[str, Any]) -> str:
        """Chunk sonuÃ§larÄ±nÄ± birleÅŸtirip final analiz oluÅŸtur"""
        # Chunk sonuÃ§larÄ±nÄ± birleÅŸtir
        combined_analysis = "\n\n".join([
            f"### {source.replace('_data', '').title()}:\n{result}"
            for source, result in chunk_results.items()
        ])
        
        # Get summary stats
        summary_stats = self._get_analysis_summary_stats(analysis_data)
        
        synthesis_prompt = f"""Hedef: {target}

AÅŸaÄŸÄ±daki parÃ§alÄ± gÃ¼venlik analizlerini deÄŸerlendirdim:

{combined_analysis}

## Ã–zet Ä°statistikler:
{json.dumps(summary_stats, indent=2, ensure_ascii=False)}

Bu analizleri birleÅŸtirerek kapsamlÄ± bir gÃ¼venlik deÄŸerlendirmesi yap:

1. **GENEL RÄ°SK SEVÄ°YESÄ°** (Kritik/YÃ¼ksek/Orta/DÃ¼ÅŸÃ¼k)

2. **ANA BULGULAR** (3-4 Ã¶nemli nokta)

3. **Ã–NERÄ°LER** (Pratik Ã¶neriler)

4. **SONUÃ‡** (Net sonuÃ§ ve eylem Ã¶nerisi)

Profesyonel ve Ã¶zet bir analiz sun (maksimum 300 kelime):"""
        
        response = self._make_openai_request([
            {
                "role": "system",
                "content": "Sen kÄ±demli bir siber gÃ¼venlik uzmanÄ±sÄ±n. ParÃ§alÄ± analizleri birleÅŸtirerek kapsamlÄ± deÄŸerlendirmeler yapÄ±yorsun."
            },
            {
                "role": "user",
                "content": synthesis_prompt
            }
        ], max_tokens=600, temperature=0.2)  # Free tier iÃ§in optimize edilmiÅŸ synthesis
        
        return response.choices[0].message.content.strip()

    def _assess_threat_level(self, analysis_data: Dict[str, Any]) -> str:
        """Threat seviyesini belirle API Ã§aÄŸrÄ±larÄ±nÄ± optimize etmek iÃ§in"""
        score = 0
        
        # VirusTotal skorlarÄ±
        vt = analysis_data.get('virustotal_data', {})
        if vt and 'error' not in vt:
            score += vt.get('malicious_count', 0) * 3
            score += vt.get('suspicious_count', 0) * 1
        
        # URLScan skorlarÄ±
        urlscan = analysis_data.get('urlscan_data', {})
        if urlscan and 'error' not in urlscan:
            score += urlscan.get('malicious_domains', 0) * 2
            score += urlscan.get('suspicious_domains', 0) * 1
        
        # AbuseIPDB skorlarÄ±
        abuse = analysis_data.get('abuseipdb_data', {})
        if abuse and 'error' not in abuse:
            confidence = abuse.get('abuse_confidence', 0)
            if confidence > 75:
                score += 3
            elif confidence > 50:
                score += 2
            elif confidence > 25:
                score += 1
        
        # Skorlara gÃ¶re threat level belirle
        if score >= 8:
            return 'HIGH'
        elif score >= 3:
            return 'MEDIUM'
        else:
            return 'LOW'

    def _generate_step_fallback_analysis(self, step_name: str, step_data: Dict[str, Any], error: str) -> str:
        """Tek bir step iÃ§in fallback analiz oluÅŸtur"""
        if error == "low_priority_skipped":
            return f"{step_name} analizi: DÃ¼ÅŸÃ¼k priorite nedeniyle atlandÄ± (API kotasÄ± korunmasÄ±)"
        
        # Basit kural tabanlÄ± analiz
        if 'virustotal' in step_name.lower():
            malicious = step_data.get('malicious_count', 0)
            if malicious > 0:
                return f"VirusTotal: {malicious} gÃ¼venlik motoru zararlÄ± olarak iÅŸaretlemiÅŸ (YÃ¼ksek Risk)"
            else:
                return "VirusTotal: ZararlÄ± iÃ§erik tespit edilmedi (Temiz)"
        
        elif 'urlscan' in step_name.lower():
            malicious_domains = step_data.get('malicious_domains', 0)
            if malicious_domains > 0:
                return f"URLScan: {malicious_domains} zararlÄ± domain tespit edildi (Risk var)"
            else:
                return "URLScan: ZararlÄ± domain tespit edilmedi (Temiz)"
        
        elif 'abuseipdb' in step_name.lower():
            confidence = step_data.get('abuse_confidence', 0)
            if confidence > 50:
                return f"AbuseIPDB: %{confidence} kÃ¶tÃ¼ye kullanÄ±m gÃ¼veni (Dikkatli olunmalÄ±)"
            else:
                return "AbuseIPDB: DÃ¼ÅŸÃ¼k kÃ¶tÃ¼ye kullanÄ±m riski (Temiz)"
        
        return f"{step_name}: Analiz tamamlanamadÄ± ({error})"

    def _generate_fallback_comprehensive_analysis(self, analysis_data: Dict[str, Any], error: str) -> str:
        """Generate rule-based comprehensive analysis when AI fails"""
        try:
            # Risk seviyesini belirle
            risk_factors = []
            total_threats = 0
            
            # URLScan verileri analizi
            urlscan = analysis_data.get('urlscan_data', {})
            if urlscan and 'error' not in urlscan:
                malicious_domains = urlscan.get('malicious_domains', 0)
                suspicious_domains = urlscan.get('suspicious_domains', 0)
                if malicious_domains > 0:
                    risk_factors.append(f"URLScan: {malicious_domains} zararlÄ± domain")
                    total_threats += malicious_domains
                if suspicious_domains > 0:
                    risk_factors.append(f"URLScan: {suspicious_domains} ÅŸÃ¼pheli domain")
            
            # VirusTotal verileri analizi
            vt = analysis_data.get('virustotal_data', {})
            if vt and 'error' not in vt:
                malicious = vt.get('malicious_count', 0)
                suspicious = vt.get('suspicious_count', 0)
                if malicious > 0:
                    risk_factors.append(f"VirusTotal: {malicious} motor zararlÄ± tespit")
                    total_threats += malicious
                if suspicious > 0:
                    risk_factors.append(f"VirusTotal: {suspicious} motor ÅŸÃ¼pheli tespit")
            
            # AbuseIPDB verileri analizi
            abuse = analysis_data.get('abuseipdb_data', {})
            if abuse and 'error' not in abuse:
                confidence = abuse.get('abuse_confidence', 0)
                reports = abuse.get('total_reports', 0)
                if confidence > 50:
                    risk_factors.append(f"AbuseIPDB: %{confidence} kÃ¶tÃ¼ye kullanÄ±m gÃ¼veni")
                    total_threats += 1
                if reports > 0:
                    risk_factors.append(f"AbuseIPDB: {reports} kÃ¶tÃ¼ye kullanÄ±m raporu")
            
            # Risk seviyesi belirleme
            if total_threats >= 5:
                risk_level = "KRÄ°TÄ°K"
            elif total_threats >= 3:
                risk_level = "YÃœKSEK"
            elif total_threats >= 1:
                risk_level = "ORTA"
            elif len(risk_factors) > 0:
                risk_level = "DÃœÅÃœK"
            else:
                risk_level = "DÃœÅÃœK"
            
            # Hata mesajÄ±na gÃ¶re Ã¶zel durumlar
            error_note = ""
            if 'quota' in error.lower() or '429' in error:
                error_note = "\nğŸ’¡ Not: AI analizi OpenAI API kotasÄ± nedeniyle kullanÄ±lamÄ±yor."
            elif 'timeout' in error.lower():
                error_note = "\nğŸ’¡ Not: AI analizi baÄŸlantÄ± zaman aÅŸÄ±mÄ± nedeniyle kullanÄ±lamÄ±yor."
            else:
                error_note = "\nğŸ’¡ Not: AI analizi teknik hata nedeniyle kullanÄ±lamÄ±yor."
            
            return f"""## GENEL RÄ°SK SEVÄ°YESÄ°: {risk_level}

### ANA BULGULAR:
{"- " + chr(10).join(risk_factors) if risk_factors else "- TÃ¼m gÃ¼venlik kaynaklarÄ± temiz sonuÃ§ verdi"}
{"- Bilinen tehdit tespit edilmedi" if total_threats == 0 else f"- Toplam {total_threats} gÃ¼venlik tehdidi tespit edildi"}
- Genel gÃ¼venlik durumu {"iyi" if total_threats == 0 else "dikkat gerektiriyor"}

### Ã–NERÄ°LER:
{"- Normal gÃ¼venlik Ã¶nlemleri yeterli" if total_threats == 0 else "- Ek gÃ¼venlik Ã¶nlemleri alÄ±nmalÄ±"}
- GÃ¼ncel gÃ¼venlik yazÄ±lÄ±mÄ± kullanmaya devam edin
- DÃ¼zenli gÃ¼venlik taramasÄ± yapÄ±n
{"- ÅÃ¼pheli aktiviteler iÃ§in sistemi izleyin" if total_threats > 0 else ""}

### SONUÃ‡:
{risk_level.lower().capitalize()} risk seviyesi. {"Hedef gÃ¼venli gÃ¶rÃ¼nÃ¼yor ancak sÃ¼rekli dikkatli olun." if total_threats == 0 else "Dikkatli olun ve ek gÃ¼venlik Ã¶nlemleri deÄŸerlendirin."}
{error_note}

Not: Bu analiz AI desteÄŸi olmadan temel kurallara dayalÄ± olarak oluÅŸturulmuÅŸtur."""
            
        except Exception as fallback_error:
            logger.error(f"Fallback comprehensive analysis error: {str(fallback_error)}")
            return f"""## GENEL RÄ°SK SEVÄ°YESÄ°: DÃœÅÃœK

### ANA BULGULAR:
- Temel gÃ¼venlik analizi tamamlandÄ±
- AI analizi kullanÄ±lamadÄ±

### Ã–NERÄ°LER:
- Manuel gÃ¼venlik incelemesi yapÄ±n
- GÃ¼ncel gÃ¼venlik yazÄ±lÄ±mÄ± kullanÄ±n

### SONUÃ‡:
Manuel inceleme Ã¶nerilir. AI analizi ÅŸu anda kullanÄ±lamÄ±yor.

Not: Bu temel analiz kurallara dayalÄ± olarak oluÅŸturulmuÅŸtur."""

    def _format_single_source_data(self, source: str, data: Dict[str, Any]) -> Dict[str, Any]:
        """Format data for single source analysis"""
        if source == 'urlscan_data':
            return {
                'Tarama Durumu': data.get('page_status'),
                'ZararlÄ± Domain SayÄ±sÄ±': data.get('malicious_domains', 0),
                'ÅÃ¼pheli Domain SayÄ±sÄ±': data.get('suspicious_domains', 0),
                'Genel DeÄŸerlendirme': data.get('overall_verdict', {}),
                'Ãœlke': data.get('country'),
                'IP': data.get('ip'),
                'Motor DeÄŸerlendirmeleri': data.get('engines_verdict', {})
            }
        elif source == 'virustotal_data':
            return {
                'Hedef Tipi': data.get('target_type'),
                'ZararlÄ± Tespit': data.get('malicious_count', 0),
                'ÅÃ¼pheli Tespit': data.get('suspicious_count', 0),
                'Temiz Tespit': data.get('clean_count', 0),
                'Toplam Motor': data.get('total_engines', 0),
                'Reputation Skoru': data.get('reputation', 0),
                'Ãœlke': data.get('country'),
                'Kategoriler': data.get('categories', {})
            }
        elif source == 'abuseipdb_data':
            return {
                'IP Adresi': data.get('ip_address'),
                'KÃ¶tÃ¼ye KullanÄ±m GÃ¼veni': f"%{data.get('abuse_confidence', 0)}",
                'Toplam Rapor': data.get('total_reports', 0),
                'Risk Seviyesi': data.get('risk_level'),
                'Ãœlke': data.get('country_name'),
                'ISP': data.get('isp'),
                'Beyaz Liste': data.get('is_whitelisted'),
                'Son Rapor': data.get('last_reported_at')
            }
        return data

    def _get_analysis_summary_stats(self, analysis_data: Dict[str, Any]) -> Dict[str, Any]:
        """Get summary statistics from all analyses"""
        stats = {
            'toplam_kaynak': 0,
            'basarili_kaynak': 0,
            'toplam_tehdit_tespiti': 0,
            'en_yÃ¼ksek_risk_skoru': 0
        }
        
        sources = ['urlscan_data', 'virustotal_data', 'abuseipdb_data']
        
        for source in sources:
            stats['toplam_kaynak'] += 1
            data = analysis_data.get(source, {})
            
            if data and 'error' not in data:
                stats['basarili_kaynak'] += 1
                
                # Count threats
                if source == 'urlscan_data':
                    threats = data.get('malicious_domains', 0) + data.get('suspicious_domains', 0)
                    stats['toplam_tehdit_tespiti'] += threats
                elif source == 'virustotal_data':
                    threats = data.get('malicious_count', 0) + data.get('suspicious_count', 0)
                    stats['toplam_tehdit_tespiti'] += threats
                    # Update max risk score
                    if data.get('total_engines', 0) > 0:
                        risk_ratio = (data.get('malicious_count', 0) / data.get('total_engines', 1)) * 100
                        stats['en_yÃ¼ksek_risk_skoru'] = max(stats['en_yÃ¼ksek_risk_skoru'], risk_ratio)
                elif source == 'abuseipdb_data':
                    confidence = data.get('abuse_confidence', 0)
                    if confidence > 25:
                        stats['toplam_tehdit_tespiti'] += 1
                    stats['en_yÃ¼ksek_risk_skoru'] = max(stats['en_yÃ¼ksek_risk_skoru'], confidence)
        
        return stats

    def _generate_comprehensive_fallback_analysis(self, target: str, analysis_data: Dict[str, Any]) -> Dict[str, Any]:
        """Generate comprehensive fallback analysis using enhanced rule-based analyzer"""
        try:
            # Use the enhanced rule-based analyzer for comprehensive analysis
            analysis_result = self.enhanced_rule_analyzer.analyze_comprehensive(target, analysis_data)
            
            # Format the response in the expected structure
            return {
                'analysis': analysis_result.get('final_comprehensive_analysis', 'GeliÅŸmiÅŸ kural tabanlÄ± analiz tamamlandÄ±.'),
                'risk_score': analysis_result.get('risk_level', 'Medium'),
                'recommendations': [],  # Enhanced analyzer doesn't return recommendations in this format
                'summary': {
                    'total_sources': len([k for k in analysis_data.keys() if '_data' in k and 'error' not in analysis_data.get(k, {})]),
                    'threat_level': analysis_result.get('risk_level', 'Medium'),
                    'confidence': analysis_result.get('confidence', 'Medium'),
                    'threat_count': analysis_result.get('threat_count', 0),
                    'numeric_score': analysis_result.get('risk_score', 50)
                },
                'individual_analyses': analysis_result.get('step_analyses', {}),
                'method': 'enhanced_rule_based',
                'fallback_reason': 'AI unavailable - using enhanced rule-based analysis'
            }
        except Exception as e:
            logger.error(f"Enhanced rule analyzer failed: {e}")
            # Fallback to basic rule analysis
            return self._generate_basic_fallback_analysis(target, analysis_data)
    
    def _generate_basic_fallback_analysis(self, target: str, analysis_data: Dict[str, Any]) -> Dict[str, Any]:
        """Generate basic fallback analysis when enhanced analyzer fails"""
        step_analyses = {}
        
        # Individual source analyses
        urlscan_data = analysis_data.get('urlscan_data', {})
        if urlscan_data and 'error' not in urlscan_data:
            malicious = urlscan_data.get('malicious_domains', 0)
            suspicious = urlscan_data.get('suspicious_domains', 0)
            if malicious > 0 or suspicious > 0:
                step_analyses['urlscan_data'] = f"URLScan.io: {malicious} zararlÄ± ve {suspicious} ÅŸÃ¼pheli domain tespit edildi. Bu, hedefin riskli olabileceÄŸini gÃ¶steriyor."
            else:
                step_analyses['urlscan_data'] = "URLScan.io: ZararlÄ± veya ÅŸÃ¼pheli iÃ§erik tespit edilmedi. Hedef bu aÃ§Ä±dan gÃ¼venli gÃ¶rÃ¼nÃ¼yor."
        else:
            step_analyses['urlscan_data'] = "URLScan.io verisi mevcut deÄŸil."
        
        virustotal_data = analysis_data.get('virustotal_data', {})
        if virustotal_data and 'error' not in virustotal_data:
            malicious = virustotal_data.get('malicious_count', 0)
            total = virustotal_data.get('total_engines', 0)
            if malicious > 0:
                step_analyses['virustotal_data'] = f"VirusTotal: {malicious}/{total} gÃ¼venlik motoru zararlÄ± olarak iÅŸaretledi. Risk seviyesi yÃ¼ksek."
            else:
                step_analyses['virustotal_data'] = f"VirusTotal: {total} gÃ¼venlik motorunun hiÃ§biri zararlÄ± olarak iÅŸaretlemedi. Temiz gÃ¶rÃ¼nÃ¼yor."
        else:
            step_analyses['virustotal_data'] = "VirusTotal verisi mevcut deÄŸil."
        
        abuseipdb_data = analysis_data.get('abuseipdb_data', {})
        if abuseipdb_data and 'error' not in abuseipdb_data:
            confidence = abuseipdb_data.get('abuse_confidence', 0)
            reports = abuseipdb_data.get('total_reports', 0)
            if confidence > 50:
                step_analyses['abuseipdb_data'] = f"AbuseIPDB: %{confidence} kÃ¶tÃ¼ye kullanÄ±m gÃ¼veni ile yÃ¼ksek risk. {reports} kÃ¶tÃ¼ye kullanÄ±m raporu mevcut."
            elif confidence > 0:
                step_analyses['abuseipdb_data'] = f"AbuseIPDB: %{confidence} kÃ¶tÃ¼ye kullanÄ±m gÃ¼veni ile dÃ¼ÅŸÃ¼k-orta risk. {reports} rapor mevcut."
            else:
                step_analyses['abuseipdb_data'] = "AbuseIPDB: KÃ¶tÃ¼ye kullanÄ±m raporu bulunmuyor. Temiz IP adresi."
        else:
            step_analyses['abuseipdb_data'] = "AbuseIPDB verisi mevcut deÄŸil."
        
        # Generate final analysis
        threat_count = 0
        if urlscan_data and (urlscan_data.get('malicious_domains', 0) > 0 or urlscan_data.get('suspicious_domains', 0) > 0):
            threat_count += 1
        if virustotal_data and virustotal_data.get('malicious_count', 0) > 0:
            threat_count += 1
        if abuseipdb_data and abuseipdb_data.get('abuse_confidence', 0) > 25:
            threat_count += 1
        
        if threat_count >= 2:
            risk_level = "YÃœKSEK"
            final_analysis = f"""
## GENEL RÄ°SK SEVÄ°YESÄ°: {risk_level}

### ANA BULGULAR:
- Birden fazla gÃ¼venlik kaynaÄŸÄ± tehdit tespit etti
- Bu hedef potansiyel olarak zararlÄ± olabilir
- Dikkatli yaklaÅŸÄ±m gereklidir

### Ã–NERÄ°LER:
- Bu hedefe eriÅŸimden kaÃ§Ä±nÄ±n
- GÃ¼venlik yazÄ±lÄ±mÄ±nÄ±zÄ± gÃ¼ncel tutun
- ÅÃ¼pheli aktivite iÃ§in izleme yapÄ±n

### SONUÃ‡:
YÃ¼ksek risk tespit edildi. Bu hedefle etkileÅŸime girmeden Ã¶nce ek gÃ¼venlik Ã¶nlemleri alÄ±n.

Not: Bu analiz AI desteÄŸi olmadan temel kurallara dayalÄ± olarak oluÅŸturulmuÅŸtur.
"""
        elif threat_count == 1:
            risk_level = "ORTA"
            final_analysis = f"""
## GENEL RÄ°SK SEVÄ°YESÄ°: {risk_level}

### ANA BULGULAR:
- Bir gÃ¼venlik kaynaÄŸÄ± potansiyel risk tespit etti
- DiÄŸer kaynaklar temiz gÃ¶steriyor
- Orta dÃ¼zeyde dikkat gerekli

### Ã–NERÄ°LER:
- Dikkatli ÅŸekilde eriÅŸim saÄŸlayÄ±n
- GÃ¼venlik yazÄ±lÄ±mÄ±nÄ±zÄ± aktif tutun
- ÅÃ¼pheli davranÄ±ÅŸ gÃ¶zlemleyin

### SONUÃ‡:
Orta seviye risk. Standart gÃ¼venlik Ã¶nlemleri ile dikkatli eriÅŸim saÄŸlanabilir.

Not: Bu analiz AI desteÄŸi olmadan temel kurallara dayalÄ± olarak oluÅŸturulmuÅŸtur.
"""
        else:
            risk_level = "DÃœÅÃœK"
            final_analysis = f"""
## GENEL RÄ°SK SEVÄ°YESÄ°: {risk_level}

### ANA BULGULAR:
- TÃ¼m gÃ¼venlik kaynaklarÄ± temiz sonuÃ§ verdi
- Bilinen tehdit tespit edilmedi
- Genel gÃ¼venlik durumu iyi

### Ã–NERÄ°LER:
- Normal gÃ¼venlik Ã¶nlemleri yeterli
- GÃ¼ncel gÃ¼venlik yazÄ±lÄ±mÄ± kullanmaya devam edin
- DÃ¼zenli gÃ¼venlik taramasÄ± yapÄ±n

### SONUÃ‡:
DÃ¼ÅŸÃ¼k risk seviyesi. Hedef gÃ¼venli gÃ¶rÃ¼nÃ¼yor ancak sÃ¼rekli dikkatli olun.

Not: Bu analiz AI desteÄŸi olmadan temel kurallara dayalÄ± olarak oluÅŸturulmuÅŸtur.
"""
        
        return {
            'step_by_step_analysis': step_analyses,
            'final_comprehensive_analysis': final_analysis,
            'analysis_method': 'fallback_rule_based',
            'ai_error_message': "âš ï¸ AI analiz yapÄ±lamadÄ±: Kural tabanlÄ± analiz uygulandÄ±"
        }
    
    def _format_data_for_ai(self, target: str, analysis_data: Dict[str, Any]) -> Dict[str, Any]:
        """Format analysis data for AI consumption"""
        formatted_data = {}
        
        # URLScan data
        urlscan_data = analysis_data.get('urlscan_data', {})
        if urlscan_data and 'error' not in urlscan_data:
            formatted_data['URLScan'] = {
                'ZararlÄ± domain sayÄ±sÄ±': urlscan_data.get('malicious_domains', 0),
                'ÅÃ¼pheli domain sayÄ±sÄ±': urlscan_data.get('suspicious_domains', 0),
                'Genel deÄŸerlendirme': urlscan_data.get('overall_verdict', {}),
                'Ãœlke': urlscan_data.get('country'),
                'IP adresi': urlscan_data.get('ip'),
                'Durum': urlscan_data.get('page_status')
            }
        
        # VirusTotal data
        virustotal_data = analysis_data.get('virustotal_data', {})
        if virustotal_data and 'error' not in virustotal_data:
            formatted_data['VirusTotal'] = {
                'ZararlÄ± tespit eden motor sayÄ±sÄ±': virustotal_data.get('malicious_count', 0),
                'ÅÃ¼pheli tespit eden motor sayÄ±sÄ±': virustotal_data.get('suspicious_count', 0),
                'Temiz tespit eden motor sayÄ±sÄ±': virustotal_data.get('clean_count', 0),
                'Toplam motor sayÄ±sÄ±': virustotal_data.get('total_engines', 0),
                'Reputation skoru': virustotal_data.get('reputation', 0),
                'Kategoriler': virustotal_data.get('categories', {}),
                'Hedef tipi': virustotal_data.get('target_type')
            }
        
        # AbuseIPDB data
        abuseipdb_data = analysis_data.get('abuseipdb_data', {})
        if abuseipdb_data and 'error' not in abuseipdb_data:
            formatted_data['AbuseIPDB'] = {
                'IP adresi': abuseipdb_data.get('ip_address'),
                'KÃ¶tÃ¼ye kullanÄ±m gÃ¼ven yÃ¼zdesi': abuseipdb_data.get('abuse_confidence', 0),
                'Toplam rapor sayÄ±sÄ±': abuseipdb_data.get('total_reports', 0),
                'Risk seviyesi': abuseipdb_data.get('risk_level'),
                'Ãœlke': abuseipdb_data.get('country_name'),
                'ISP': abuseipdb_data.get('isp'),
                'Beyaz listede mi': abuseipdb_data.get('is_whitelisted')
            }
        
        return formatted_data
    
    def _create_analysis_prompt(self, target: str, formatted_data: Dict[str, Any]) -> str:
        """Create analysis prompt for AI"""
        prompt = f"""
Hedef: {target}

Elimde aÅŸaÄŸÄ±daki gÃ¼venlik verilerini var:

{json.dumps(formatted_data, indent=2, ensure_ascii=False)}

Bu verileri bir siber gÃ¼venlik uzmanÄ± gibi analiz et ve aÅŸaÄŸÄ±daki konularÄ± kapsayan detaylÄ± bir deÄŸerlendirme yap:

1. GENEL RÄ°SK SEVÄ°YESÄ°: Bu hedefin genel risk seviyesi nedir? (DÃ¼ÅŸÃ¼k/Orta/YÃ¼ksek/Kritik)

2. TESPÄ°T EDÄ°LEN TEHDITLER: Hangi potansiyel tehditler tespit edildi?

3. VERÄ° ANALÄ°ZÄ°: Her bir kaynaktan gelen veriler ne anlama geliyor?

4. Ã–NERÄ°LER: Bu hedefe karÅŸÄ± hangi gÃ¼venlik Ã¶nlemleri alÄ±nmalÄ±?

5. SONUÃ‡: KÄ±sa ve net bir sonuÃ§ Ã¶zeti.

LÃ¼tfen analizi mesleki, anlaÅŸÄ±lÄ±r ve TÃ¼rkÃ§e olarak yap. Teknik terimler kullanÄ±rken aÃ§Ä±klama da ekle.
        """
        return prompt
    
    def _generate_fallback_analysis(self, target: str, analysis_data: Dict[str, Any]) -> str:
        """Generate basic analysis when AI is not available"""
        analysis_parts = []
        analysis_parts.append(f"Hedef: {target}")
        analysis_parts.append("\n=== GÃœVENLIK ANALÄ°ZÄ° ===")
        
        # Analyze URLScan data
        urlscan_data = analysis_data.get('urlscan_data', {})
        if urlscan_data and 'error' not in urlscan_data:
            malicious = urlscan_data.get('malicious_domains', 0)
            suspicious = urlscan_data.get('suspicious_domains', 0)
            if malicious > 0 or suspicious > 0:
                analysis_parts.append(f"\nâš ï¸ URLScan.io: {malicious} zararlÄ±, {suspicious} ÅŸÃ¼pheli domain tespit edildi.")
            else:
                analysis_parts.append(f"\nâœ… URLScan.io: ZararlÄ± veya ÅŸÃ¼pheli iÃ§erik tespit edilmedi.")
        
        # Analyze VirusTotal data
        virustotal_data = analysis_data.get('virustotal_data', {})
        if virustotal_data and 'error' not in virustotal_data:
            malicious = virustotal_data.get('malicious_count', 0)
            total = virustotal_data.get('total_engines', 0)
            if malicious > 0:
                analysis_parts.append(f"\nâš ï¸ VirusTotal: {malicious}/{total} gÃ¼venlik motoru zararlÄ± olarak iÅŸaretledi.")
            else:
                analysis_parts.append(f"\nâœ… VirusTotal: HiÃ§bir gÃ¼venlik motoru zararlÄ± olarak iÅŸaretlemedi.")
        
        # Analyze AbuseIPDB data
        abuseipdb_data = analysis_data.get('abuseipdb_data', {})
        if abuseipdb_data and 'error' not in abuseipdb_data:
            confidence = abuseipdb_data.get('abuse_confidence', 0)
            reports = abuseipdb_data.get('total_reports', 0)
            if confidence > 0:
                analysis_parts.append(f"\nâš ï¸ AbuseIPDB: %{confidence} kÃ¶tÃ¼ye kullanÄ±m gÃ¼veni, {reports} rapor var.")
            else:
                analysis_parts.append(f"\nâœ… AbuseIPDB: KÃ¶tÃ¼ye kullanÄ±m raporu bulunmuyor.")
        
        # Generate recommendation
        analysis_parts.append("\n=== Ã–NERÄ°LER ===")
        
        # Check if any threats detected
        threats_detected = False
        if urlscan_data and (urlscan_data.get('malicious_domains', 0) > 0 or urlscan_data.get('suspicious_domains', 0) > 0):
            threats_detected = True
        if virustotal_data and virustotal_data.get('malicious_count', 0) > 0:
            threats_detected = True
        if abuseipdb_data and abuseipdb_data.get('abuse_confidence', 0) > 25:
            threats_detected = True
        
        if threats_detected:
            analysis_parts.append("ğŸš¨ Bu hedef riskli gÃ¶rÃ¼nÃ¼yor. EriÅŸimden kaÃ§Ä±nÄ±n ve gÃ¼venlik Ã¶nlemlerinizi artÄ±rÄ±n.")
        else:
            analysis_parts.append("âœ… Mevcut veriler hedefin gÃ¼venli olduÄŸunu gÃ¶steriyor, ancak sÃ¼rekli dikkatli olun.")
        
        analysis_parts.append("\nNot: Bu analiz AI desteÄŸi olmadan temel kurallara dayalÄ± olarak oluÅŸturulmuÅŸtur.")
        
        return "\n".join(analysis_parts)
    
    def _generate_demo_analysis(self, source_name: str, data: dict) -> str:
        """Generate demo analysis when AI is not available"""
        if 'urlscan' in source_name.lower():
            malicious = data.get('malicious_domains', 0)
            suspicious = data.get('suspicious_domains', 0)
            if malicious > 0:
                return f"URLScan.io taramasÄ±nda {malicious} zararlÄ± domain tespit edildi. Bu site gÃ¼venli deÄŸil."
            elif suspicious > 0:
                return f"URLScan.io taramasÄ±nda {suspicious} ÅŸÃ¼pheli domain tespit edildi. Dikkatli olunmalÄ±."
            else:
                return "URLScan.io taramasÄ±nda herhangi bir gÃ¼venlik tehdidi tespit edilmedi. Site temiz gÃ¶rÃ¼nÃ¼yor."
        
        elif 'virustotal' in source_name.lower():
            malicious = data.get('malicious_count', 0)
            suspicious = data.get('suspicious_count', 0)
            clean = data.get('clean_count', 0)
            if malicious > 0:
                return f"VirusTotal'da {malicious} antivirus motoru zararlÄ± yazÄ±lÄ±m tespit etti. Risk yÃ¼ksek."
            elif suspicious > 0:
                return f"VirusTotal'da {suspicious} antivirus motoru ÅŸÃ¼pheli aktivite bildirdi. Orta risk."
            else:
                return f"VirusTotal'da {clean} antivirus motoru temiz rapor verdi. GÃ¼venli gÃ¶rÃ¼nÃ¼yor."
        
        elif 'abuseipdb' in source_name.lower():
            confidence = data.get('abuse_confidence', 0)
            reports = data.get('total_reports', 0)
            if confidence > 75:
                return f"AbuseIPDB'de %{confidence} gÃ¼venle kÃ¶tÃ¼ye kullanÄ±m tespit edildi. Bu IP tehlikeli."
            elif confidence > 25:
                return f"AbuseIPDB'de %{confidence} gÃ¼venle ÅŸÃ¼pheli aktivite rapor edildi. Dikkat edilmeli."
            else:
                return "AbuseIPDB'de herhangi bir kÃ¶tÃ¼ye kullanÄ±m raporu bulunmadÄ±. IP temiz gÃ¶rÃ¼nÃ¼yor."
        
        return f"{source_name} verisi analiz edildi. Manuel inceleme Ã¶nerilir."
    
    def _generate_step_fallback_analysis(self, source_name: str, data: dict, error: str) -> str:
        """Generate fallback analysis for step-by-step analysis when AI API fails"""
        # Check if it's a clean source
        if error == "clean_source":
            if 'urlscan' in source_name.lower():
                return "URLScan.io: ZararlÄ± veya ÅŸÃ¼pheli iÃ§erik tespit edilmedi. Hedef bu aÃ§Ä±dan gÃ¼venli gÃ¶rÃ¼nÃ¼yor."
            elif 'virustotal' in source_name.lower():
                clean = data.get('clean_count', 0)
                total = data.get('total_engines', 0)
                return f"VirusTotal: {total} gÃ¼venlik motorunun hiÃ§biri zararlÄ± olarak iÅŸaretlemedi. Temiz gÃ¶rÃ¼nÃ¼yor."
            elif 'abuseipdb' in source_name.lower():
                return "AbuseIPDB: KÃ¶tÃ¼ye kullanÄ±m raporu bulunmuyor. Temiz IP adresi."
        
        # Provide source-specific fallback analysis for threats
        if 'urlscan' in source_name.lower():
            malicious = data.get('malicious_domains', 0)
            suspicious = data.get('suspicious_domains', 0) 
            if malicious > 0 or suspicious > 0:
                return f"URLScan.io: {malicious} zararlÄ±, {suspicious} ÅŸÃ¼pheli domain tespit edildi. Manuel inceleme gerekli."
            else:
                return "URLScan.io: ZararlÄ± veya ÅŸÃ¼pheli iÃ§erik tespit edilmedi. Hedef bu aÃ§Ä±dan gÃ¼venli gÃ¶rÃ¼nÃ¼yor."
                
        elif 'virustotal' in source_name.lower():
            malicious = data.get('malicious_count', 0)
            total = data.get('total_engines', 0)
            if malicious > 0:
                return f"VirusTotal: {malicious}/{total} gÃ¼venlik motoru zararlÄ± olarak iÅŸaretledi. Dikkat gerekli."
            else:
                return f"VirusTotal: {total} gÃ¼venlik motorunun hiÃ§biri zararlÄ± olarak iÅŸaretlemedi. Temiz gÃ¶rÃ¼nÃ¼yor."
                
        elif 'abuseipdb' in source_name.lower():
            confidence = data.get('abuse_confidence', 0)
            reports = data.get('total_reports', 0)
            if confidence > 50 or reports > 0:
                return f"AbuseIPDB: %{confidence} gÃ¼ven skoruyla {reports} kÃ¶tÃ¼ye kullanÄ±m raporu var. Risk mevcut."
            else:
                return "AbuseIPDB: KÃ¶tÃ¼ye kullanÄ±m raporu bulunmuyor. Temiz IP adresi."
                
        return f"{source_name}: Manuel inceleme gerekli (AI analizi kullanÄ±lamÄ±yor)."
    
    def _generate_error_fallback_analysis(self, data: dict, error: str) -> str:
        """Generate fallback analysis when AI API fails"""
        if 'quota' in error.lower() or '429' in error:
            return "AI analizi geÃ§ici olarak kullanÄ±lamÄ±yor (API quota sÄ±nÄ±rÄ±). Manuel deÄŸerlendirme: TÃ¼m kaynaklardan alÄ±nan verilere gÃ¶re manuel risk analizi yapÄ±labilir."
        else:
            return f"AI analizi sÄ±rasÄ±nda teknik hata oluÅŸtu. Ham veriler Ã¼zerinden manuel inceleme yapÄ±labilir."
    
    def _generate_fallback_comprehensive_analysis(self, analysis_data: dict, error: str) -> str:
        """Generate comprehensive fallback analysis when AI API fails"""
        analysis_parts = []
        
        if 'quota' in error.lower() or '429' in error:
            analysis_parts.append("ğŸ¤– AI Analizi GeÃ§ici Olarak KullanÄ±lamÄ±yor")
            analysis_parts.append("\nOpenAI API quota sÄ±nÄ±rÄ±na ulaÅŸÄ±ldÄ±. AÅŸaÄŸÄ±da temel gÃ¼venlik deÄŸerlendirmesi sunulmaktadÄ±r:")
        else:
            analysis_parts.append("ğŸ¤– AI Analizi HatasÄ±")
            analysis_parts.append(f"\nTeknik hata nedeniyle AI analizi yapÄ±lamadÄ±. Temel deÄŸerlendirme:")
        
        analysis_parts.append("\n" + "="*50)
        analysis_parts.append("ğŸ“Š TEMEL GÃœVENLÄ°K DEÄERLENDÄ°RMESÄ°")
        analysis_parts.append("="*50)
        
        # Analyze URLScan data
        urlscan_data = analysis_data.get('urlscan_data', {})
        if urlscan_data and 'error' not in urlscan_data:
            malicious = urlscan_data.get('malicious_domains', 0)
            suspicious = urlscan_data.get('suspicious_domains', 0)
            analysis_parts.append(f"\nğŸ” URLScan.io SonuÃ§larÄ±:")
            if malicious > 0:
                analysis_parts.append(f"   âš ï¸ {malicious} zararlÄ± domain tespit edildi - YÃœKSEKRÄ°SK")
            elif suspicious > 0:
                analysis_parts.append(f"   âš ï¸ {suspicious} ÅŸÃ¼pheli domain tespit edildi - ORTA RÄ°SK")
            else:
                analysis_parts.append("   âœ… ZararlÄ± veya ÅŸÃ¼pheli domain tespit edilmedi")
        
        # Analyze VirusTotal data
        virustotal_data = analysis_data.get('virustotal_data', {})
        if virustotal_data and 'error' not in virustotal_data:
            malicious = virustotal_data.get('malicious_count', 0)
            suspicious = virustotal_data.get('suspicious_count', 0)
            total = virustotal_data.get('total_engines', 0)
            analysis_parts.append(f"\nğŸ›¡ï¸ VirusTotal SonuÃ§larÄ±:")
            if malicious > 0:
                analysis_parts.append(f"   âš ï¸ {malicious}/{total} gÃ¼venlik motoru zararlÄ± tespit etti - YÃœKSEK RÄ°SK")
            elif suspicious > 0:
                analysis_parts.append(f"   âš ï¸ {suspicious}/{total} gÃ¼venlik motoru ÅŸÃ¼pheli tespit etti - ORTA RÄ°SK")
            else:
                analysis_parts.append(f"   âœ… {total} gÃ¼venlik motorunun hiÃ§biri zararlÄ± tespit etmedi")
        
        # Analyze AbuseIPDB data
        abuseipdb_data = analysis_data.get('abuseipdb_data', {})
        if abuseipdb_data and 'error' not in abuseipdb_data:
            confidence = abuseipdb_data.get('abuse_confidence', 0)
            reports = abuseipdb_data.get('total_reports', 0)
            analysis_parts.append(f"\nğŸš¨ AbuseIPDB SonuÃ§larÄ±:")
            if confidence > 75:
                analysis_parts.append(f"   âš ï¸ %{confidence} gÃ¼venle kÃ¶tÃ¼ye kullanÄ±m tespit edildi - YÃœKSEK RÄ°SK")
            elif confidence > 25:
                analysis_parts.append(f"   âš ï¸ %{confidence} gÃ¼venle ÅŸÃ¼pheli aktivite - ORTA RÄ°SK")
            else:
                analysis_parts.append("   âœ… KÃ¶tÃ¼ye kullanÄ±m raporu bulunmuyor")
        
        # Overall assessment
        analysis_parts.append("\n" + "="*50)
        analysis_parts.append("ğŸ¯ GENEL DEÄERLENDÄ°RME")
        analysis_parts.append("="*50)
        
        # Determine overall risk
        high_risk_indicators = 0
        medium_risk_indicators = 0
        
        if urlscan_data:
            if urlscan_data.get('malicious_domains', 0) > 0:
                high_risk_indicators += 1
            elif urlscan_data.get('suspicious_domains', 0) > 0:
                medium_risk_indicators += 1
        
        if virustotal_data:
            if virustotal_data.get('malicious_count', 0) > 0:
                high_risk_indicators += 1
            elif virustotal_data.get('suspicious_count', 0) > 0:
                medium_risk_indicators += 1
        
        if abuseipdb_data:
            confidence = abuseipdb_data.get('abuse_confidence', 0)
            if confidence > 75:
                high_risk_indicators += 1
            elif confidence > 25:
                medium_risk_indicators += 1
        
        if high_risk_indicators > 0:
            analysis_parts.append("\nğŸš¨ YÃœKSEK RÄ°SK TESPIT EDÄ°LDÄ°!")
            analysis_parts.append("   â€¢ Bu hedefle etkileÅŸime geÃ§mekten kaÃ§Ä±nÄ±n")
            analysis_parts.append("   â€¢ GÃ¼venlik duvarÄ± kurallarÄ±nÄ±zÄ± gÃ¶zden geÃ§irin")
            analysis_parts.append("   â€¢ Sistem yÃ¶neticinizi bilgilendirin")
        elif medium_risk_indicators > 0:
            analysis_parts.append("\nâš ï¸ ORTA DÃœZEYRÄ°SK TESPIT EDÄ°LDÄ°")
            analysis_parts.append("   â€¢ Dikkatli olun ve ek gÃ¼venlik Ã¶nlemleri alÄ±n")
            analysis_parts.append("   â€¢ Bu hedefle etkileÅŸimi sÄ±nÄ±rlayÄ±n")
            analysis_parts.append("   â€¢ SÃ¼rekli izleme yapÄ±n")
        else:
            analysis_parts.append("\nâœ… DÃœÅÃœK RÄ°SK")
            analysis_parts.append("   â€¢ Mevcut veriler gÃ¼venli olduÄŸunu gÃ¶steriyor")
            analysis_parts.append("   â€¢ Yine de temel gÃ¼venlik kurallarÄ±na uyun")
            analysis_parts.append("   â€¢ Periyodik kontroller yapmaya devam edin")
        
        analysis_parts.append("\n" + "="*50)
        analysis_parts.append("ğŸ“ NOT: Bu analiz AI desteÄŸi olmadan temel kurallar")
        analysis_parts.append("Ã§erÃ§evesinde yapÄ±lmÄ±ÅŸtÄ±r. Daha detaylÄ± analiz iÃ§in")
        analysis_parts.append("OpenAI API quota'nÄ±zÄ± yenilemeniz Ã¶nerilir.")
        analysis_parts.append("="*50)
        
        return "\n".join(analysis_parts)
